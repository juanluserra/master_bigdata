---
title: "Práctica 5"
output: html_document
date: "2024-10-16"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
datos <- read.csv("~/1º BIG DATA/master_bigdata/APRENDIZAJE ESTADISTICO/datos.csv", stringsAsFactors=TRUE)
attach(datos)

# Analizamos los datos
summary(datos)
plot(datos)
```

```{r}
# Realizamos un ajuste lineal general
glm.fit <- glm(Y ~ X, data = datos)
coef(glm.fit)

# Realizamos un ajuste lineal
lm.fit <- lm(Y ~ X, data = datos)
coef(lm.fit)

# Se puede ver como los resultados son idénticos
```

```{r}
# Usaremos la librería boot
library(boot)

# Generamos el error dado por los coeficientes delta
cv.err <- cv.glm(datos, glm.fit)
cv.err$delta
```

```{r}
# Realizamos lo mismo para diferentes valores de grado de polinomio
cv.error <- rep(0, 5)

for (i in 1:5){
  glm.fit <- glm(Y ~ poly(X, i), data = datos)
  cv.error[i] <- cv.glm(datos, glm.fit)$delta[1]
}
cv.error

# Se puede ver como el menor error se da en el grado 3
```

```{r}
# Realizamos un ajuste para visualizarlo
glm.fit <- glm(Y ~ poly(X, 3), data = datos)

plot(X, Y)
predict.glm <- predict(glm.fit, data.frame(x = X))
lines(X, predict.glm, col="red")
```

```{r}
# Creamos la función de error estándar
alpha.fn <- function(data, index){
  
  X <- data$X[index]
  Y <- data$Y[index]
  
  return(
    (var(Y) - cov(X,Y)) / (var(X)+var(Y)-2*cov(X,Y))
  )
  
}

# Ejecutamos el boot con los datos y la función
boot(datos, alpha.fn, R=1000)
```

```{r}
# Vamos a estimar la precisión del modelo lineal con bootstraping

# Creamos una función boot
boot.fn <- function(data, index){
  return(
    coef( lm(Y ~ X, data = datos,  subset = index) )
  )
}


```

test