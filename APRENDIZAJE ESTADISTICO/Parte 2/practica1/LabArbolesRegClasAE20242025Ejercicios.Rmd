---
title: "Árboles de clasificación y regresión con Rpart. Ejercicios"
author: "Aprendizaje Estadístico, Máster en Tecnologías de Análisis de Datos Masivos: Big Data. Profesor: Juan A. Botía (juanbot@um.es)"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    highlight: kate
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




# Ejercicios

## Ejercicio 1

**Enunciado:** Dibuja un ejemplo (de tu propia invención) de una partición del espacio de características bidimensional que podría resultar de una división binaria recursiva. Tu ejemplo debe contener al menos seis regiones. Dibuja un árbol de decisión correspondiente a esta partición. Asegúrate de etiquetar todos los aspectos de tus figuras, incluidas las regiones $R_1,R_2,\ldots,$ los puntos de corte $t_1,t_2,\ldots$ y así sucesivamente.

**Resolución**

La forma más sencilla de hacer esto de forma más o menos metódica es siguiendo unos pasos

* Paso 0: Dibuja primero unos ejes $x$ e $y$, naturalmente perpendiculares entre sí. Toma el eje $x$ como el eje de trabajo. 

* Paso 1: Elige un punto de corte en el eje de trabajo. Traza una línea perpendicular al interior del área $x \geq 0$, $y\geq 0$, delimitada por ambos ejes.

* Paso 2: Pasa al otro eje como eje de trabajo. Elige un punto de corte en ese eje. Ahora elige entre el propio eje, o una de las líneas paralelas ya trazadas en el espacio bidimensional ya trazadas. Traza una línea perpendicular a la altura del punto de corte elegido, en la dirección que se desee. Ir al Paso 2. 

## Ejercicio 2


Considera el índice de Gini, el error de clasificación y la entropía en un problema de clasificación binario. Crea un solo gráfico que muestre cada una de estas cantidades como una función de $\hat{p}_{m1}$. El eje x debe mostrar $\hat{p}_{m1}$, desde 0 a 1, y el eje y debe mostrar el índice de Gini, la entropía y el error de clasificación. Nota que $\hat{p}_{m1}=1−\hat{p}_{m2}$ en un problema de clase binaria.


```{r}
p <- seq(0, 1, length = 100)
gini <- 2 * p * (1 - p)
entropy <- -p * log2(p) - (1 - p) * log2(1 - p)
classerr <- 1 - pmax(1 - p, p)
entropy[is.na(entropy)] <- 0

plot(p, gini,
     type = "l", col = "blue", lwd = 2, ylab = "Score", xlab = "Probabilidad de la clase 1",
     main = "Gini, entropía y error de clasificación", ylim = c(0, 1)
)
lines(p, entropy, col = "red", lwd = 2)
lines(p, classerr, col = "green", lwd = 2)
legend("topleft", legend = c("Gini", "Entropía", "Error"), col = c("blue", "red", "green"), lwd = 2)
```

## Ejercicio 3

Este problema implica el conjunto de datos OJ, que forma parte del paquete ISLR2.

```{r}
library(rpart)
library(rpart.plot)
library(summarytools)
library(ISLR2)
data(OJ)
print(dfSummary(OJ), method = "render")
```


Crea un conjunto de entrenamiento que contenga una muestra aleatoria de 800 observaciones y un conjunto de prueba con las observaciones restantes.

```{r}
set.seed(1)
train <- sample(1:nrow(OJ), 800)
OJ.test <- OJ[-train, ]
Purchase.test <- OJ$Purchase[-train]
```


b. Ajusta un árbol rpart a los datos de entrenamiento, con Purchase como la respuesta y las otras variables como predictores. Usa la función summary() para producir estadísticas de resumen sobre el árbol y describe los resultados obtenidos. ¿Cuál sería el mejor árbol? ¿Cuántos nodos terminales tiene el árbol?

```{r}
tree.OJ <- rpart(Purchase ~ ., OJ, subset = train, method = "class", maxsurrogate = 0)
summary(tree.OJ)
```


c. Escribe el nombre del objeto árbol para obtener una salida detallada en texto. Elige uno de los nodos terminales e interpreta la información mostrada.

```{r}
print(tree.OJ)
```


d. Crea un gráfico del árbol e interpreta los resultados.

```{r}
rpart.plot(tree.OJ)
```


e. Predice la respuesta en los datos de prueba y produce una matriz de confusión comparando las etiquetas de prueba con las etiquetas de prueba predichas. ¿Cuál es la tasa de error de prueba?

```{r}
tree.pred <- predict(tree.OJ, OJ.test, type = "class")
table(tree.pred, Purchase.test)
print(paste0("El error de test es  ", 1 - MLmetrics::Accuracy(tree.pred, Purchase.test)))
```


f. Aplica la función printcp() al conjunto de entrenamiento para determinar el tamaño óptimo del árbol.

```{r}
printcp(tree.OJ)
```

g. Produce un gráfico con el tamaño del árbol en el eje x y la tasa de error de clasificación validada cruzada en el eje y.

```{r}
plot(tree.OJ$cptable[, "nsplit"], tree.OJ$cptable[, "xerror"],
     type = "l",
     col = "blue", lwd = 2, ylab = "X error", xlab = "Número de nodos internos",
     main = "Error de validación cruzada"
)
```


h. ¿Qué tamaño de árbol corresponde a la tasa de error de clasificación validada cruzada más baja?

Según la tabla, parece que el tamaño más grande.

i. Produce un árbol podado correspondiente al tamaño óptimo del árbol obtenido utilizando validación cruzada. Si la validación cruzada no lleva a la selección de un árbol podado, entonces crea un árbol podado con cinco nodos terminales.

```{r}
fit5 <- prune(tree.OJ, cp = 0.015873)
rpart.plot(fit5)
tree.pred <- predict(fit5, OJ.test, type = "class")
table(tree.pred, Purchase.test)
```


j. Compara las tasas de error de entrenamiento entre los árboles podados y no podados. ¿Cuál es mayor?

```{r}
train.pred <- predict(tree.OJ, OJ[train, ], type = "class")
train5.pred <- predict(fit5, OJ[train, ], type = "class")
print(paste0("El error de train del árbol completo es  ", 1 - MLmetrics::Accuracy(train.pred, OJ$Purchase[train])))
print(paste0("El error de train del podado es ", 1 - MLmetrics::Accuracy(train5.pred, OJ$Purchase[train])))
```


k. Compara las tasas de error de prueba entre los árboles podados y no podados. ¿Cuál es mayor?

```{r}
test.pred <- predict(tree.OJ, OJ[-train, ], type = "class")
test5.pred <- predict(fit5, OJ[-train, ], type = "class")
print(paste0("El error de test del árbol completo es  ", 1 - MLmetrics::Accuracy(test.pred, OJ$Purchase[-train])))
print(paste0("El error de test del podado es ", 1 - MLmetrics::Accuracy(test5.pred, OJ$Purchase[-train])))
```

