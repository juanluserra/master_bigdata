{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKDnY3vSahxH"
      },
      "source": [
        "#Whisper by OpenAI\n",
        "\n",
        "Whisper es un sistema ASR (Automatic Speech Recognition) multilingüe desarrollado por OpenAI utilizando tecnologías de Transformers que puede usarse con las librerías de openai-whisper.\n",
        "Es importante seleccionar en el entorno de ejecución el uso de GPU para que funcione bien.\n",
        "*texto en cursiva*\n",
        "En este cuaderno se muestra un ejemplo para la asignatura TGINE del máster de Big Data de la Universidad de Murcia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oV_l79Bxa4RR"
      },
      "outputs": [],
      "source": [
        "#instalamos las librerías necesarias\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "from IPython.display import Audio\n",
        "#descargamos un ejemplo de audio en español para ser transcrito\n",
        "!wget https://valencia.inf.um.es/valencia-tgine/audio.mp3\n",
        "\n",
        "audio = \"audio.mp3\"\n",
        "Audio (audio)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#descargamos un ejemplo de audio en español para ser transcrito\n",
        "!wget https://valencia.inf.um.es/valencia-tgine/audio_en.mp3\n",
        "\n",
        "audio_en = \"audio_en.mp3\"\n",
        "Audio (audio_en)"
      ],
      "metadata": {
        "id": "drE0vjkgmBfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um1qv2miacqX"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import torch\n",
        "\n",
        "# empty the cache of GPU\n",
        "torch.cuda.empty_cache()\n",
        "model = whisper.load_model(\"medium\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH9h--cujlW1"
      },
      "source": [
        "Cargamos un ejemplo en español"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2laqfOrKjKwB"
      },
      "outputs": [],
      "source": [
        "# load audio and pad/trim it to fit 30 seconds\n",
        "audio = whisper.load_audio(\"audio.mp3\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "# make log-Mel spectrogram and move to the same device as the model\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# detect the spoken language\n",
        "_, probs = model.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "# decode the audio\n",
        "options = whisper.DecodingOptions()\n",
        "result = whisper.decode(model, mel, options)\n",
        "\n",
        "# print the recognized text\n",
        "print(result.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0bMdtBujoWZ"
      },
      "source": [
        "Cargamos ahora un ejemplo en inglés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiiXrRazkvQy"
      },
      "outputs": [],
      "source": [
        "# load audio and pad/trim it to fit 30 seconds\n",
        "audio = whisper.load_audio(\"audio_en.mp3\")\n",
        "audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "# make log-Mel spectrogram and move to the same device as the model\n",
        "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "# detect the spoken language\n",
        "_, probs = model.detect_language(mel)\n",
        "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
        "\n",
        "# decode the audio\n",
        "options = whisper.DecodingOptions()\n",
        "result = whisper.decode(model, mel, options)\n",
        "\n",
        "# print the recognized text\n",
        "print(result.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVR4k9bYvv8V"
      },
      "source": [
        "#Otros ASR en Hugging face\n",
        "\n",
        "Hay otros modelos ASR en Huggingface que se pueden cargar con la librería huggingsound.\n",
        "\n",
        "Unos ejmplos son los siguientes:\n",
        "\n",
        "Español\n",
        "- https://huggingface.co/facebook/wav2vec2-large-xlsr-53-spanish\n",
        "- https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-spanish\n",
        "\n",
        "Inglés\n",
        "- https://huggingface.co/facebook/s2t-large-librispeech-asr\n",
        "\n",
        "Sin embargo, estos modelos no son multilingües y no tienen la recuperación de la puntuación incluída.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}