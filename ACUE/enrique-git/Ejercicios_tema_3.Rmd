---
title: "Lab_2.Tema3"
output: html_document
---

```{r}
#install.packages("recommenderlab",dependencies = T)
library(recommenderlab)
data(Jester5k)
```

- Sección 5.4. Inspecciona las propiedades del dataset Jester5k.

```{r}
r <- sample(Jester5k, 1000)
as(r[1,], "list")
print(rowCounts(r[1,]))
rowMeans(r[1,])
hist(getRatings(r), breaks=100)
hist(getRatings(normalize(r, method="Z-score")), breaks=100)

hist(rowCounts(r), breaks=50)
hist(colMeans(r), breaks=20)
```

- Crea un imagen de las 100 primeras filas y columnas de la matriz con el comando: image(Jester5k[1:100,1:100]). ¿Qué usuarios son los qué aportan más ratings?¿Qué chistes han sido más valorados (número de valoraciones)?


```{r}
image(Jester5k[1:100,1:100])
r <- Jester5k[1:100,1:100]
v<-NULL
for(i in 1:100){
  v[i] <- length(getRatings(r[i,]))
}

ch <- NULL
for(i in 1:100){
  s <- as(r[,i], "list")
  s<- s[lapply(s,length)>0]
  ch[i] <- length(s)
}
which( v == max(v) )

```

Los usuarios `which( v == max(v) )` son los que aportan más ratings (valoran 100 chistes).

Los chistes `which( ch == max(ch) )` son los que más veces son valorados (son valorados 100 veces).

- Sección 5.5. Crea un recomendador siguiendo las indicaciones del tutorial. Crea otra versión del recomendador sólo con los 100 primeros usuarios y vuelve a predecir para los usuarios 1001 y 1002. ¿Detectas diferencias en las recomendaciones?

```{r}
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
r <- Recommender(Jester5k[1:1000], method = "POPULAR")
recom <- predict(r, Jester5k[1001:1002], n=5)
as(recom, "list")

```

```{r}
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
r <- Recommender(Jester5k[1:1000], method = "UBCF")
recom <- predict(r, Jester5k[1001:1002], n=5)
as(recom, "list") 
```

```{r}
r <- Recommender(Jester5k[1:1000], method = "IBCF")
recom <- predict(r, Jester5k[1001:1002], n=5)
as(recom, "list")
```

```{r}
r <- Recommender(Jester5k[1:100], method = "IBCF")
recom <- predict(r, Jester5k[1001:1002], n=5)
as(recom, "list")
```

```{r}
r <- Recommender(Jester5k[1:100], method = "POPULAR")
recom <- predict(r, Jester5k[1001:1002], n=5)
as(recom, "list")
```

Sí hay diferencias claro.

```{r}
recom <- predict(r, Jester5k[1001:1002], type="ratings")
recom
as(recom, "matrix")[,1:10]

recom <- predict(r, Jester5k[1001:1002], type="ratingMatrix")
recom
as(recom, "matrix")[,1:10]
```




- Secciones 5.6 y 5.7. Evalúa las recomendaciones siguiendo el tutorial.
¿Qué diferencia hay entre la evaluación de la sección 5.6 y la 5.7? ¿Cuál
te parece más apropiada para un sistema de recomendación?


```{r}
#5.6
e <- evaluationScheme(Jester5k[1:1000], method="split", train=0.9, given=15, goodRating=5)
r1 <- Recommender(getData(e, "train"), "UBCF")
r2 <- Recommender(getData(e, "train"), "IBCF")
p1 <- predict(r1, getData(e, "known"), type="ratings")
p2 <- predict(r2, getData(e, "known"), type="ratings")

error <- rbind(calcPredictionAccuracy(p1, getData(e, "unknown")),calcPredictionAccuracy(p2, getData(e, "unknown")))
rownames(error) <- c("UBCF","IBCF")
error
#5.7
scheme <- evaluationScheme(Jester5k[1:1000], method="cross", k=5, given=15, goodRating=5)
results <- evaluate(scheme, method = "UBCF", type="topNList", n=c(1,3,5,7,10))
getConfusionMatrix(results)[[1]]
avg(results)
plot(results, annotate=TRUE)
plot(results, "prec/rec", annotate=TRUE)
```

```{r}
# 5.7 bis
scheme <- evaluationScheme(Jester5k[1:1000], method="cross", k=4, given=3, goodRating=5)

results <- evaluate(scheme, method="IBCF", n=c(1,3,5,10,15,20))
getConfusionMatrix(results)[[1]]
avg(results)

plot(results, annotate=TRUE)

plot(results, "prec/rec", annotate=TRUE)
```

-Sección 5.8. Compara los diferentes métodos de recomendación en esta
sección. ¿Cómo quedaría el algoritmo de recomendación ítem-based en
comparación con los utilizados en esta sección?¿Cambian los resultados
si modificamos el particionamiento utilizado en el procedimiento de
evaluación?

```{r}
scheme <- evaluationScheme(Jester5k[1:1000], method="split", train = .9, k=1, given=20, goodRating=5)
algorithms <- list(
  "random items" = list(name="RANDOM", param=NULL),
  "popular items" = list(name="POPULAR", param=NULL),
  "user-based CF" = list(name="UBCF", param=list(method="Cosine",
                                                 nn=50, minRating=3)),
  "item-based CF" = list(name="IBCF",  param=list(k=50))
  
  )
results <- evaluate(scheme, algorithms, type = "topNList", n=c(1, 3, 5, 10, 15, 20))
results
plot(results, annotate=c(1,3), legend="topleft")
plot(results, "prec/rec", annotate=3)
```

```{r}
scheme <- evaluationScheme(Jester5k[1:1000], method="cross", k=4, given=3, goodRating=5)
algorithms <- list(
  "user-based CF" = list(name="UBCF", param=list(method="Cosine",
                                                 nn=50, minRating=3)),
  "item-based CF" = list(name="IBCF", param=NULL)
  
  )
results <- evaluate(scheme, algorithms, n=c(1, 3, 5, 10, 15, 20))
results
plot(results, annotate=c(1,3), legend="topleft")
plot(results, "prec/rec", annotate=3)
```






```{r}
methods <- c("UBCF", "IBCF", "SVD")
evaluations <- lapply(methods, function(method) {
  model <- Recommender(Jester5k, method = method)
  evaluate(model, method = "topNList", type = "ratings")
})

# Imprimir los resultados de la evaluación
for (i in seq_along(methods)) {
  print(paste("Method:", methods[i]))
  print(evaluations[[i]])
}
```



http://www.r-bloggers.com/testing-recommender-systems-in-r/
