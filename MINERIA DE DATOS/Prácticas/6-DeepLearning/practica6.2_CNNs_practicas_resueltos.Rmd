---
title: "Minería de Datos: ejercicios de redes neuronales convolucionales con Keras en R"
subtitle: "Master en Análisis de datos masivos, Big Data (UMU)"
author: "Aurora González Vidal, `aurora.gonzalez2@um.es`"
date: "25/03/2025"
output: 
  html_document:
    theme: spacelab
    highlight: kate
    df_print: paged
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(keras)
```


# Ejercicio sobre parámetros

Dado el siguiente modelo, calcular el número de parámetros a entrenar de la red. Diferenciar entre la cantidad de parámetros de la red y la memoria que la red necesita para hacer una inferencia. ¿En qué se diferencian?. Pista: cada parámetro suele almacenarse en 32 bits (4 bytes, precisión simple).

```{r,eval=F}
# Define Model -----------------------------------------------------------
input_shape = c(32,32,1)
num_classes = 10
model <- keras_model_sequential()
model %>%
  layer_conv_2d(filters = 32, kernel_size = c(5,5), activation = 'relu',
                input_shape = input_shape) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_dropout(rate = 0.25) %>% 
  layer_flatten() %>% 
  layer_dense(units = 128, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes, activation = 'softmax')

```

Suponemos para el ejercicio que input_shape es $32\times 32 \times 1$.
Esta especificación de red neuronal va a producir los parámetros como sigue: 

* La primera capa de convolución va a crear volúmenes (mapas de características) de tamaño $32-5+1\times 32-5+1 = 28\times 28$. Se crearán tantos volúmenes como filtros tenemos, por lo tanto, a la salida se generan 32 mapas de $28\times 28$. Estos pasarán a ser la entrada de la siguiente capa. 

En este caso, se generarán $5\times 5\times 32 + 32=832$ parámetros (nótese que cada kernel llevará un un sesgo asociado). Otra forma de ver este mismo cálculo consiste en que cada kernel (filtro) genera $5\times 5 +1 = 26$ parámetros, y $26 \times 32=832$

* La capa de max_pooling no genera parámetros, pero convierte el volumen de $28\times 28$ en volúmenes de $14\times 14$. Así, los 32 volúmenes de $14\times 14$ se transforman en un tensor de tamaño $14\times 14\times 32=6272$ (tamaño del tensor de salida).

* La capa `layer_flatten()` transforma ese tensor en un vector de 1 dimensión pero no añade parámetros a optimizar. Los nodos de entrada son $14\times 14\times 32$ y se conectan a otros 128 nodos, de forma densa, llevando cada uno de esos 128 nodos un sesgo adicional. Esto nos da lugar a $6272\times 128 + 128=802944$ parámetros.

* Como sabemos, la capa de drop-out no añade parámetros ni ocupa espacio en memoria.

* Finalmente, la capa densa final añade $128\times 10 + 10=1290$ parámetros (128 neuronas de la capa anterior, 10 neuronas de salida y 10 sesgos un por neurona).

Recapitulando, el total de parámetros de la red es $832 + 802944 + 1290=805066$. Adicionalmente, se van a necesitar tensores $T_{32,28,28}$, $T_{32,14,14}$, vectores de 6272 componentes, 128 y 10.


```{r}
(32-5+1)^2+(32-5+1) #Se calcula esto
5*5*32+32 #Se entrena esto -> Los parámetros del kernel 5x5 * los 32 filtros + el sesgo
#Después del pooling tenemos un volumen 14x14x32(misma profundidad y mitad de anchura y altura)
14*14*32*128+128 #Parámetros de la salida del flatten por número de nodos + sesgo
128*10+10 #Nodos de la capa oculta por los nodos a la salida
```

MEMORIA INFERENCIA:
(A) Memoria para almacenar los parámetros: 805066×4B=3.22 MB

(b) Memoria para los tensores intermedios
Tensor $T_{32,28,28}$:  32\times28\times28\times4B=100352B=0.1MB
Tensor $T_{32,14,14}$: 32\times14\times14\times4B=25088B=0.025MB
$T_{32,14,14}$
Vector de 6272 componentes: 6272\times4B=0.025MB
Vector de 128 componentes: 128\times4B=0.0005MB
Vector de 10 componentes: 10\times4B=0.00004MB

Sumando: 0.1+0.025+0.025+0.0005+0.00004=0.15MB

Y en total: 3.22MB+0.15MB=3.37MB

Parámetros entrenables = cantidad de pesos y sesgos ajustados en el entrenamiento (805066 en este caso).

Memoria en inferencia = incluye parámetros + tensores de activación necesarios para procesar una muestra.

Diferencia clave: En inferencia no se almacenan gradientes ni se necesita memoria para retropropagación, por lo que la memoria usada es menor.

# Ejercicio sobre AlexNet

En el fragmento de código de abajo, se proporciona una implementación en Keras de la arquitectura AlexNet,  que, en principio, no aparece asociada a ningún dataset. Pero esta red se creó para trabajar sobre el ImageNet Challenge de 2010. Podemos encontrar más detalles sobre este modelo en  [aquí](https://d2l.ai/chapter_convolutional-modern/alexnet.html):

```{python,eval=F}
import tensorflow as tf
from d2l import tensorflow as d2l

def net():
  return tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4,
  activation='relu'),
  tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
  tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',
  activation='relu'),
  tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
  tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',
  activation='relu'),
  tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',
  activation='relu'),
  tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',
  activation='relu'),
  tf.keras.layers.MaxPool2D(pool_size=3, strides=2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(4096, activation='relu'),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(4096, activation='relu'),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(10)
  ])
```
  
  
  1. Describir la arquitectura. Calcular los parámetros entrenables de la red.
  
  2. Implementar la arquitectura AlexNet en R-Keras. 
  
  Recordemos que en AlexNet, las imágenes tenían un tamaño de $224\times 224\times 3$, con tres canales de color (detalles [aquí](https://paperswithcode.com/dataset/imagenet)). Y que el número de objetos diferentes que pueden reconocerse es de 1000.
  
3. Usa tu implementación de AlexNet en R Keras para, adaptándola, generar modelos para el conjunto Fashion MNIST haciendo uso del código que hemos visto anteriormente.

El conjunto está disponible en <https://keras.rstudio.com/reference/dataset_fashion_mnist.html>. Detalles técnicos sobre el dataset están en el paper  [fashion MNIST](http://arxiv.org/abs/1708.07747), y en su [GitHub](https://github.com/zalandoresearch/fashion-mnist).
  
La definición del modelo es la siguiente.
  
  ```{r,eval=F}
# Define Model -----------------------------------------------------------
input_shape = c(224,224,3)
num_classes = 1000
model <- keras_model_sequential()
model %>%
layer_conv_2d(filters = 96, kernel_size = c(11,11),strides = 4, 
activation = 'relu',
input_shape = input_shape) %>% 
layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>% 
layer_conv_2d(filters = 256, kernel_size = c(5,5), padding = 'same', 
activation = 'relu') %>% 
layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>%
layer_conv_2d(filters = 384, kernel_size = c(3,3), padding = 'same', 
activation = 'relu') %>%
layer_conv_2d(filters = 384, kernel_size = c(3,3), padding = 'same', 
activation = 'relu') %>%
layer_conv_2d(filters = 256, kernel_size = c(3,3), padding = 'same', 
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>%
layer_flatten() %>% 
layer_dense(units = 4096, activation = 'relu') %>% 
layer_dropout(rate = 0.5) %>% 
layer_dense(units = 4096, activation = 'relu') %>% 
layer_dropout(rate = 0.5) %>% 
layer_dense(units = num_classes, activation = 'softmax')
```

Que nos da lugar a casi 51M de parámetros.


1.Describir la arquitectura. Calcular los parámetros entrenables de la red.
```{r}
#Entrada de imágenes 224*224*3
11*11*96+96 # kernel de 11*11, 96 filtros y sesgo, aquí tendríamos un output shape de 214,214,3
```


2.Implementar la arquitectura AlexNet en R-Keras.

```{r}
input_shape = c(224,224,3)
num_classes = 1000
model <- keras_model_sequential()
model %>%
  layer_conv_2d(filters=96, kernel_size = c(11,11), strides = 4, activation = 'relu', input_shape=input_shape) %>%
  layer_max_pooling_2d(pool_size = c(3, 3), strides = 2) %>% 
  layer_conv_2d(filters = 256, kernel_size = c(5,5),padding = "same", activation = 'relu') %>%
  layer_max_pooling_2d(pool_size = c(3, 3), strides = 2) %>% 
  layer_conv_2d(filters = 384, kernel_size = c(3,3),padding = "same", activation = 'relu') %>%
  layer_conv_2d(filters = 384, kernel_size = c(3,3),padding = "same", activation = 'relu') %>%
  layer_conv_2d(filters = 256, kernel_size = c(3,3),padding = "same", activation = 'relu') %>%
  layer_max_pooling_2d(pool_size = c(3, 3), strides = 2) %>% 
  layer_flatten() %>% 
  layer_dense(units = 4096, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 4096, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes, activation = 'softmax')
```
```{r}
(224-11+4+0)/4
```

```{r}
summary(model)
```



El dataset es idéntico a MNIST, solo hay que cambiar el acceso al conjunto de datos.

```{r,eval=F}
library(keras)
# Data Preparation -----------------------------------------------------
num_classes <- 10
# Input image dimensions
img_rows <- 28
img_cols <- 28

# The data, shuffled and split between train and test sets
mnist <- dataset_fashion_mnist()
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y

x_train <- array_reshape(x_train, c(nrow(x_train), img_rows, img_cols, 1))
x_test <- array_reshape(x_test, c(nrow(x_test), img_rows, img_cols, 1))
input_shape <- c(img_rows, img_cols, 1)

# Transform RGB values into [0,1] range
x_train <- x_train / 255
x_test <- x_test / 255

cat('x_train_shape:', dim(x_train), '\n')
cat(nrow(x_train), 'train samples\n')
cat(nrow(x_test), 'test samples\n')

# Convert class vectors to binary class matrices
y_train <- to_categorical(y_train, num_classes)
y_test <- to_categorical(y_test, num_classes)
```

Pero AlexNet está diseñado para aceptar imágenes muy complejas. Piénsese que se usan capas de convolución de 96, 256, 384, 384 y 256 kernels respectivamente. Además, el tamaño del kernel de la primera capa es excesivamente grande para este tipo de figuras. Además de ser figuras simples, son también considerablemente más pequeñas (de $224\times 224\times 3$ pasamos a $28\times 28\times 1$). Por tanto, el primer kernel ha de encogerse.

Por todo esto, definimos el modelo, cambiando el kernel size a 3x3, con un stride de 1, y un input shape de 28x28x1 para poder procesar la entrada. 


```{r,eval=F}
# Define Model -----------------------------------------------------------
input_shape = c(img_rows,img_cols,1)
model <- keras_model_sequential()
model %>%
  layer_conv_2d(filters = 96, kernel_size = c(3,3),strides = 1, 
                activation = 'relu',
                input_shape = input_shape) %>% 
  layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>% 
  layer_conv_2d(filters = 256, kernel_size = c(5,5), padding = 'same', 
                activation = 'relu') %>% 
  layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>%
  layer_conv_2d(filters = 384, kernel_size = c(3,3), padding = 'same', 
                activation = 'relu') %>%
  layer_conv_2d(filters = 384, kernel_size = c(3,3), padding = 'same', 
                activation = 'relu') %>%
  layer_conv_2d(filters = 256, kernel_size = c(3,3), padding = 'same', 
                activation = 'relu') %>%
  layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>%
  layer_flatten() %>% 
  layer_dense(units = 4096, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 4096, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes, activation = 'softmax')
```


Y el mecanismo para entrenar, como siempre, lo definimos en una función


```{r,eval=F}
batch_size <- 128
epochs <- 5

train_evaluate = function(model, x_train,y_train,batch_size,epochs,x_test,y_test){
  model %>% compile(
    loss = loss_categorical_crossentropy,
    optimizer = optimizer_adadelta(),
    metrics = c('accuracy')
  )
  model %>% fit(
    x_train, y_train,
    batch_size = batch_size,
    epochs = epochs,
    verbose = 1,
    validation_data = list(x_test, y_test)
  )
  scores <- model %>% evaluate(
    x_test, y_test, verbose = 2
  )
  scores
}

scores = train_evaluate(model,x_train,y_train,batch_size,epochs,x_test,y_test)

# Output metrics
cat('Test loss:', scores[[1]], '\n')
cat('Test accuracy:', scores[[2]], '\n')
```

Este modelo no es tolerable así que lo reducimos a un mínimo para poder funcionar y volvemos a entrenar. Reducimos el MLP considerablemente, de dos capas de varios miles de nodos pasamos a una sola capa de 128 nodos. Por otro lado, nos quedamos solamente con dos capas de convolución 2D

```{r,eval=F}
# Define Model -----------------------------------------------------------
input_shape = c(img_rows,img_cols,1)
model <- keras_model_sequential()
model %>%
  layer_conv_2d(filters = 35, kernel_size = c(3,3),strides = 1, 
                activation = 'relu',
                input_shape = input_shape) %>% 
  layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>% 
  layer_conv_2d(filters = 45, kernel_size = c(5,5), padding = 'same', 
                activation = 'relu') %>% 
  layer_max_pooling_2d(pool_size = c(3, 3),strides = 2) %>%
  layer_flatten() %>% 
  layer_dense(units = 128, activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes, activation = 'softmax')

scores = train_evaluate(model,x_train,y_train,batch_size,epochs,x_test,y_test)

# Output metrics
cat('Test loss:', scores[[1]], '\n')
cat('Test accuracy:', scores[[2]], '\n')
```


# Ejercicio sobre la VGG11

Consideremos la red VGG11. ¿Cuántos parámetros en concreto tiene dicha red, si consideramos los correspondientes sesgos? Definir la red haciendo uso de R-Keras, y una vez creado el modelo, comprobar que el número de parámetros es ese, mediante `summary()`.



## 1. Entendiendo la arquitectura de VGG11

VGG11 sigue la siguiente estructura:

```{r, echo=FALSE, message=FALSE}
library(knitr)

vgg11_architecture <- data.frame(
  Bloque = c(1, "", 2, "", 3, "", "", 4, "", "", 5, "", "", "FC", "", "", ""),
  Capa = c("Conv1", "Pool1", "Conv2", "Pool2", "Conv3", "Conv4", "Pool3", 
           "Conv5", "Conv6", "Pool4", "Conv7", "Conv8", "Pool5", 
           "Flatten", "FC1", "FC2", "FC3"),
  Tipo = c("Conv2D", "MaxPool", "Conv2D", "MaxPool", "Conv2D", "Conv2D", "MaxPool",
           "Conv2D", "Conv2D", "MaxPool", "Conv2D", "Conv2D", "MaxPool",
           "-", "Dense", "Dense", "Dense"),
  Filtros = c(64, "-", 128, "-", 256, 256, "-", 512, 512, "-", 512, 512, "-", "-", 4096, 4096, 1000),
  Kernel = c("(3,3)", "(2,2)", "(3,3)", "(2,2)", "(3,3)", "(3,3)", "(2,2)",
             "(3,3)", "(3,3)", "(2,2)", "(3,3)", "(3,3)", "(2,2)",
             "-", "-", "-", "-"),
  Input_Shape = c("(224,224,3)", "(224,224,64)", "(112,112,64)", "(112,112,128)",
                  "(56,56,128)", "(56,56,256)", "(56,56,256)", 
                  "(28,28,256)", "(28,28,512)", "(28,28,512)",
                  "(14,14,512)", "(14,14,512)", "(14,14,512)", 
                  "(7,7,512)", "(25088)", "(4096)", "(4096)"),
  Output_Shape = c("(224,224,64)", "(112,112,64)", "(112,112,128)", "(56,56,128)",
                   "(56,56,256)", "(56,56,256)", "(28,28,256)",
                   "(28,28,512)", "(28,28,512)", "(14,14,512)",
                   "(14,14,512)", "(14,14,512)", "(7,7,512)",
                   "(25088)", "(4096)", "(4096)", "(1000)")
)

kable(vgg11_architecture, caption = "Estructura de la red VGG11", align = "c")

```


- Fórmula general:
Cada capa convolucional tiene parámetros dados por:

\[
\text{Número de parámetros} = (\text{Tamaño del kernel}^2 \times \text{Filtros previos}) \times \text{Número de filtros} + \text{Número de filtros (sesgos)}
\]

Cada capa densa (fully connected, FC) tiene:

\[
\text{Número de parámetros} = (\text{Entradas} \times \text{Salidas}) + \text{Salidas}
\]

## Cálculo por capas convolucionales

- Bloque 1, **Conv1:**
  \[
  (3 \times 3 \times 3) \times 64 + 64 = 1792
  \]

- Bloque 2, **Conv2:**
  \[
  (3 \times 3 \times 64) \times 128 + 128 = 73856
  \]

- Bloque 3, **Conv3:**:
  \[
  (3 \times 3 \times 128) \times 256 + 256 = 295168
  \]
**Conv4:**
  \[
  (3 \times 3 \times 256) \times 256 + 256 = 590080
  \]

- Bloque 4, **Conv5:**
  \[
  (3 \times 3 \times 256) \times 512 + 512 = 1180160
  \]
**Conv6:**
  \[
  (3 \times 3 \times 512) \times 512 + 512 = 2359808
  \]

-  Bloque 5, **Conv7:**
  \[
  (3 \times 3 \times 512) \times 512 + 512 = 2359808
  \]
**Conv8:**
  \[
  (3 \times 3 \times 512) \times 512 + 512 = 2359808
  \]

-  Cálculo por capas densas (FC)
**FC1 (25088 → 4096):**
  \[
  25088 \times 4096 + 4096 = 102764544
  \]
**FC2 (4096 → 4096):**
  \[
  4096 \times 4096 + 4096 = 16781312
  \]
**FC3 (4096 → 1000):**
  \[
  4096 \times 1000 + 1000 = 4097000
  \]

TOTAL: 1,792 +	73,856 +295,168 +	590,080 +	1,180,160 +	2,359,808 +	2,359,808 +	2,359,808 + 102,764,544 + 16,781,312 + 4,097,000 = 	132,863,336

```{r}
library(keras)

# Definir el modelo VGG11
model <- keras_model_sequential() %>%
  # Bloque 1
  layer_conv_2d(filters = 64, kernel_size = c(3,3), padding = "same", activation = "relu", input_shape = c(224, 224, 3)) %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  # Bloque 2
  layer_conv_2d(filters = 128, kernel_size = c(3,3), padding = "same", activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  # Bloque 3
  layer_conv_2d(filters = 256, kernel_size = c(3,3), padding = "same", activation = "relu") %>%
  layer_conv_2d(filters = 256, kernel_size = c(3,3), padding = "same", activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  # Bloque 4
  layer_conv_2d(filters = 512, kernel_size = c(3,3), padding = "same", activation = "relu") %>%
  layer_conv_2d(filters = 512, kernel_size = c(3,3), padding = "same", activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  # Bloque 5
  layer_conv_2d(filters = 512, kernel_size = c(3,3), padding = "same", activation = "relu") %>%
  layer_conv_2d(filters = 512, kernel_size = c(3,3), padding = "same", activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2,2), strides = c(2,2)) %>%
  
  # Capas totalmente conectadas
  layer_flatten() %>%
  layer_dense(units = 4096, activation = "relu") %>%
  layer_dense(units = 4096, activation = "relu") %>%
  layer_dense(units = 1000, activation = "softmax") # Para 1000 clases de ImageNet

# Mostrar el resumen del modelo
summary(model)

```




# Ejercicio sobre redes reusables

Estudia el ejemplo <https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/> para describirlo con tus propias palabras.


El ejemplo "Clasificación de imágenes mediante ajuste fino con EfficientNet" en Keras muestra cómo utilizar la técnica de transferencia de aprendizaje para clasificar imágenes de razas de perros en el conjunto de datos Stanford Dogs. La transferencia de aprendizaje implica tomar un modelo previamente entrenado en una tarea grande y general, como la clasificación de imágenes en ImageNet, y adaptarlo a una tarea específica con menos datos disponibles
Keras+1Keras+1

- Pasos principales del ejemplo:

1. Carga del conjunto de datos Stanford Dogs: El conjunto contiene imágenes de 120 razas de perros. Se descargan y preparan las imágenes, dividiéndolas en conjuntos de entrenamiento y validación.

2. Configuración de parámetros: Se definen parámetros como el tamaño de las imágenes, el tamaño del lote y el número de clases (120 razas).

3. Creación de conjuntos de datos: Se utilizan las funciones de Keras para cargar imágenes y aplicar aumentos de datos, como rotaciones y cambios de brillo, para mejorar la robustez del modelo.

4. Construcción del modelo:
    - Capa base de EfficientNetB0: Se carga el modelo EfficientNetB0 preentrenado en ImageNet, excluyendo su capa superior.
    - Congelación de capas: Las capas de la base se congelan para mantener los pesos preentrenados durante las primeras etapas del entrenamiento.
    - Capas superiores personalizadas: Se añaden capas densas y de regularización para adaptar el modelo a la clasificación de las 120 razas.

5. Compilación del modelo: Se especifica el optimizador Adam y la función de pérdida de entropía cruzada categórica, adecuada para clasificación multiclase.

6. Entrenamiento inicial: Se entrena el modelo con las capas base congeladas para ajustar las capas superiores a la nueva tarea.

7. Ajuste fino (fine-tuning): Después del entrenamiento inicial, se descongelan algunas capas de la base y se continúa el entrenamiento con una tasa de aprendizaje más baja. Esto permite ajustar los pesos de las capas preentrenadas a las características específicas del conjunto de datos de perros.

8. Evaluación del modelo: Finalmente, se evalúa el rendimiento del modelo ajustado en el conjunto de validación para medir su precisión en la clasificación de las razas de perros.

Este proceso demuestra cómo aprovechar modelos preentrenados como EfficientNetB0 para tareas específicas mediante transferencia de aprendizaje y ajuste fino, logrando buenos resultados incluso con conjuntos de datos más pequeños.
Keras.