% Clase de documento
\documentclass[12pt, letterpaper]{article}

% Paquetes
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{biblatex}
\usepackage{csquotes}
\usepackage{datetime}
\usepackage{amsmath}
\usepackage{lipsum}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{parskip}

%------------ 
% Decoración
%------------
\fancyhf{}
\setlength{\headheight}{15.71667pt}
\addtolength{\topmargin}{-3.71667pt}
\fancyhf{}

% Header
\fancyhead[L]{\textsc{\doctitle}}
\renewcommand{\sectionmark}[1]{\markright{#1}}
\fancyhead[R]{\textit{\nouppercase{\rightmark}}}

% Footer
\renewcommand{\footrulewidth}{0.4pt}
\fancyfoot[C]{Página \thepage}

% Título
\newcommand{\doctitle}{Título del documento}
\title{\doctitle}
\author{Autor}
\date{\monthname[\month] de \the\year}

% Bibliografía
\addbibresource{test.bib}

% Eliminar sangría
\setlength{\parindent}{0pt}

% Aumentar la separación entre párrafos
\setlength{\parskip}{1em plus 0.5em minus 0.2em}

%-----------
% Documento
%-----------
\begin{document}

% Mostrar header y footer
\pagestyle{fancy}

% Mostrar el título
\maketitle

% Índice
\newpage
\tableofcontents

% Contenido
\newpage
\section{Preprocesamiento de datos}

\subsection{Introducción}
\begin{itemize}
    \item El resultado de la minería de datos depende en gran medida de la calidad de los datos.
    \item El conjunto de datos estará formado por objetos
    \item Los objetos se describen por medio de atributos
    \item Un atributo tiene asociado un tipo que define de los valores que puede tomar
\end{itemize}

\subsection{Limpieza de datos}
Los errores en los datos pueden deberse a diferentes causas:
\begin{itemize}
    \item \textbf{Datos incompletos}: Pueden faltar atributos de interés, valores de los propios\ldots
    \item \textbf{Datos ruidosos}: Datos con ruido o errores, valores duplicados\ldots
    \item \textbf{Datos inconsistentes}: Datos que discrepan en códigos y nombres, en valores duplicados, etc. Por ejemplo.
    \begin{itemize}
        \item Edad = ''42'', Fecha de nacimiento = ''12/07/2015''
        \item Objetos con escala ``1,2,3'' y otros con escala ``A,B,C''
    \end{itemize}
    \item \textbf{Errores intencionados:} Datos que se introducen para encubrir falta de datos. Por ejemplo, encontrar la misma fecha de nacimiento para un gran grupo de personas ya que no tenían fecha 
\end{itemize}

\subsubsection{Datos ausentes}
Los datos ausentes pueden producir varios errores:
\begin{itemize}
    \item \textbf{Pérdida de eficacia:} Se extraen menos patronas y las conclusiones son menos concluyentes.
    \item \textbf{Complicaciones al analizar:} Surgen complicaciones debido a que hay técnicas que no están preparadas para gestionarlos.
    \item \textbf{Sesgo:} Puede haber sesgo en los datos que se extraen.
\end{itemize}

Por todo esto, al limpiar un dataset es necesario tener en cuenta los datos ausentes. Hay varias formas de detectarlos:
\begin{itemize}
    \item Generalmente se representan como valores nulos.
    \item Puede haber nulos camuflados, es decir, valores que no son nulos pero los representan. Esto se debe a que la integridad del sistema no permite introducir nulos en campos con ciertos formatos (direcciones, teléfonos, códigos postales\ldots)
\end{itemize}

\vspace{1em}
\underline{\textbf{Soluciones}}
\vspace{1em}

Vamos a ver soluciones al tratamiento de los datos ausentes:
\begin{itemize}
    \item \textbf{No hacer nada:} Hay métodos (como los árboles de decisión) que son robustos a los datos ausentes.
    \item \textbf{Eliminar los atributos:} Esta es una solución extrema que es necesaria en el alto porcentaje de nulos. En otros casos podemos encontrar un atributo dependiente de mayor calidad.
    \item \textbf{Eliminar el objeto:} Suele hacerse cuando en un problema de clasificación al clase está ausente, pero no es efectivo si el porcentaje de ausentes varía mucho entre atributos. Además, puede introducir sesgo.
    \item \textbf{Reemplazar:} Se puede reemplazar el hueco por un valor. Hay varias formas de hacerlo:
        \begin{itemize}
            \item Manualmente si no hay muchos valores ausentes.
            \item Por un valor que preserve la media o la varianza en datos numéricos, o la moda en datos nominales.
            \item Imputación: consiste en reemplazar estos valores faltantes con estimaciones o valores plausibles, permitiendo que el dataset esté completo y sea útil para el análisis. Hay varias formas de usarla:
                \begin{itemize}
                    \item Usar el valor medio (de todos los valores de los atributos o de solo los que pertenecen a la misma clase).
                    \item Usar el valor más probable.
                    \item Predecir el valor mediante alguna técnica (regresión, KNN, etc).
                \end{itemize}
            \item Mediante técnicas específicas. Por ejemplo, la detección del sexo a través del nombre.
        \end{itemize}
\end{itemize}

A pesar de que soluciones como la imputación sean técnicas muy útiles y frecuentes, hay que tener en cuenta que se sigue perdiendo información, e incluso que el dato que introducimos sea erróneo.

\subsubsection{Datos ruidosos}
Entendemos el ruido como un error o varianza aleatoria en una medición de una variable.

Existen varios métodos para eliminar el ruido:
\begin{itemize}
    \item \textbf{Discretización:} Este método suaviza un conjunto de valores consultando los vecinos. 
    \begin{itemize}
        \item Los valores ordenados se distribuyen en categorías con el mismo número de elementos (igual frecuencia, igual anchura\dots).
        \item Se sustotuyen los valores de cada categoría por otros: media, mediana, extremo más cercano\dots. 
    \end{itemize}
    \item \textbf{Regresión:} Se ajustan los valores a una función.
    \item \textbf{Clustering:} Se agrupan los valores para identificar los outliers (valores atípicos).
\end{itemize}

\subsubsection{Datos inconsistentes y discrepancias}
Antes de empezar a solucionar los datos ausentes y ruidosos hayq ue detectar las discrepancias en los datos. Las inconsistencias se deben a:
\begin{itemize}
    \item Formularios de entrada mal diseñados.
    \item Errores en los dispositivos de entrada.
    \item Error humano al introducir datos.
    \item Obsolescencia de los datos.
    \item Datos recogidos para otros usos.
    \item Formato inconsistente.
\end{itemize}

Hay dos tipos de herramientas para solucionar estos problemas:
\begin{itemize}
    \item \textbf{Depuración de datos:} Estas herramientas utilizan conocimiento en el dominio para detectar y corregir errores.
    \item \textbf{Auditoría de datos:} Encuentran discrepancias mediante un análisis que permite descubrir reglas y relaciones en los datos, detectando violaciones de estas mismas reglas.
\end{itemize} 

\subsubsection{Variables con varianza cercana a cero}
En muchos casos tendremos variables con varianza cero, es decir, de un solo valor. En otros casos, existirán variables que presentan muy poca variedad en sus resultados, es decir, con varianza cercana a cero o muy desbalanceadas. 

Para detectar estas variables se utilizan dos métricas:
\begin{itemize}
    \item \textbf{Ratio entre frecuencia y valor más frecuencte:} Este valor es 1 para variables balanceadas y crece con variables desbalanceadas.
    \item \textbf{Porcentaje de valores únicos:} Este valor es 0 para variables con un solo valor y 1 para variables con todos los valores únicos.
\end{itemize}

Con estas técnicas, si el ratio de frecuencia supera un límite establecido y el porcentaje de valores únicos cae por debajo de este, podemos considerar que la variable posee varianza cercana a cero y eliminarla.


\subsection{Transformaciones de datos}
Las técnicas de transformación nos permiten preparar los datos de forma apropiada para aplicar las técnicas de minería. La mayoría de las técnicas son \textbf{sobreyectivas} es decir, a cada valor original le corresponde un valor transformado.

Entre las técnicas de transformación tenemos:
\begin{itemize}
    \item \textbf{Suavizado:} Elimina el ruido.
    \item \textbf{Agregación:} Resume o agrega datos, usual en cubos de datos. Por ejemplo, acumular las ventanas mensuales en anuales.
    \item \textbf{Generalización:} Convierte datos de bajo a alto nivel.
    \item \textbf{Creación de atributos:} Se crean nuevos atributos a partir de los ya existentes.
    \item \textbf{Normalización:} Escala los datos a un determinado rango, usualmente $\{0,1\}$ o $\{-1,1\}$.
\end{itemize}

\subsubsection{Normalización}
Consiste en escalar los valores a un determinado rango. Es necesario ya que algunas técnicas de minería requieren que los datos estén normalizados, sobre todo en las basadas en concepto de distancia.

Destacan varios métodos de normalización:
\begin{itemize}
    \item \textbf{Normalización min-max:} Se realiza una transformación lineal sobre los datos originales.
    \[
        x' = \frac{x - \min(x)}{\max(x) - \min(x)}(\max(x') - \min(x')) + \min(x')
    \]
    \item \textbf{Normalización por transformada $z$ (z-score):} Los valores de una variable $A$ son normalizados en función de su media $\bar{A}$ y su desviación típica $\sigma_A$.
    \[
        x' = \frac{x - \bar{A}}{\sigma_A}
    \]

    Este método es útil cuando los rangos de las variables son desconocidos o existen valores anormales que dominan en la normalización.

    La desviación y la media resultantes de la nueva variable serán $1$ y $0$ respectivamente.

    \item \textbf{Normalización por escala decimal:} Este tipo de normalización se basa en el desplazamiento del punto decimal en los valores dle atributo. El número de posiciones que se desplaza el punto decimal depende del valor aboluto máximo de la variable $A$.
    \[
        x' = \frac{x}{10^j}
    \]
    donde $j$ es el entero más pequeño que hace que $\lvert x \rvert < 1$.

\end{itemize}

\subsubsection{Discretización}
La discretización es la conversión de un valor numérico a un valor nominal ordenado, que representa un intervalo o ``bin''. Un ejemplo sería al conversión de la nota en escala $\{1,10\}$ a una escala $\{A,B,C,D,E,F\}$.

Razones para discretizar:
\begin{itemize}
    \item Algunas técnicas de minería solo aceptan atributos discretos.
    \item Cuando existen ciertos umbrales significativos.
    \item Para integrar escalas diferentes.
    \item Cuando la interpretación de la escala no es lineal.
\end{itemize}

Tipos de discretización:
\begin{itemize}
    \item \textbf{Supervisada y no supervisada:} Si la técnica utiliza información sobre la clase será \textbf{supervisada}. En caso contrario diremos que es \textbf{no supervisada}.
    \item \textbf{Local o global:} Los métodos \textbf{gloales} aplican los mismos puntos de corte a todas las instancias. Por otro lado, los \textbf{locales} utilizan diferentes puntos de corte a diferentes ocnjuntos de instancias.
\end{itemize}


\subsection{Datos desbalanceados}

Se dice que en un dataset los datos están desbalancedaos cuando una o más clases presentan proporciones muy bajas respecto a las otras clases en el conjunto de entrenamiento. Un ejemplo sería el tener una clase $A$ con un 94\% y una clase $B$ co un 6\%.

En el caso de los datos desbalanceados, se espera que un modelo prediga la clase mayoritaria mejor que lo haría un clasificador que elija siempre la clase mayoritaria. Por ejemplo, en el ejemplo anterior un clasificador que prediga la clase $A$ con un 93\% sería un mal clasificador, pero si predice con un 95\% de precisión sería un buen clasificador.

Soluciones:
\begin{itemize}
    \item Utilizar técnicas de muestreo para mitigar el desbalanceo de clases.
    \item Utilizar otras medidas de rendimiento a la hora de evaluar modelos.
    \item Utilizar modelo que permitan mitigar esta problemática.
\end{itemize}

\subsubsection{Técnicas de muestreo}
Vamos a explicar las técnicas de muestreo que sirven para mitigar el desbalanceo de clases.
\begin{itemize}
    \item \textbf{Técnicas básicas:}
    \begin{itemize}
        \item \textbf{Downsampling:} Seleccionar aleatoriamente un subconjunto de todas las clases para que sus frecuencias se ajusten a la de la clase minoritaria.
        \item \textbf{Upsampling:} Realizar un muestreo aleatorio con reemplazo para que sus frecuencias se adapten a las de la clase mayoritaria.
    \end{itemize}

    \item \textbf{Otras ténicas:}
    \begin{itemize}
        \item \textbf{SMOTE:} Utiliza la información de los vecinos más cercanos para generar nuevas muestras de la clase minoritaria, haciendo así que las fronteras de la clase no se distorsionen. 
        \item \textbf{ROSE:} Esta técnica genera nuevas muestras en la vecindad de las ya existentes para equilibrar la frecuencia de clases. Es útil para problemas de clasificación binaria y se puede combinar con técnicas de sampling para evaluar modelos de aprendizaje. A la hora de generar las muestras se utiliza una distribución de probabilidad centrada en la muestra y con una matriz de covarianza concreta.
    \end{itemize}
\end{itemize}

\subsubsection{Medidas de rendimiento}
El error de clasificación y la precisión (accuracy) no son métricas apropiadas cuando tenemos métricas desbalanceadas. 



\end{document}
